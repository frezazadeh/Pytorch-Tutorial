{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4AflypI54rq",
        "outputId": "44ada4ea-eff0-4ef5-bcab-10ec66bf055e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy dtype: float64\n",
            "Tensor dtype: torch.float64\n",
            "Tensor -> float32 dtype: torch.float32\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# NumPy -> Torch shares memory (CPU only)\n",
        "np_array = np.arange(1.0, 8.0)          # dtype=float64 by default\n",
        "t_shared = torch.from_numpy(np_array)   # shares memory, keeps dtype\n",
        "\n",
        "print(\"NumPy dtype:\", np_array.dtype)       # float64\n",
        "print(\"Tensor dtype:\", t_shared.dtype)      # torch.float64\n",
        "\n",
        "# Convert to float32 explicitly (makes a NEW tensor, breaks sharing)\n",
        "t32 = t_shared.to(torch.float32)  # or: t_shared.float()\n",
        "print(\"Tensor -> float32 dtype:\", t32.dtype)  # torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Out-of-place change: new array object; tensor still points to old memory\n",
        "np_array = np_array + 1\n",
        "print(\"Tensor after np_array = np_array + 1 (out-of-place):\", t_shared)  # unchanged\n",
        "\n",
        "# In-place change: affects the shared tensor\n",
        "np_array2 = np.arange(1.0, 8.0)\n",
        "t_shared2 = torch.from_numpy(np_array2)\n",
        "np_array2 += 10  # in-place\n",
        "print(\"Tensor after np_array2 += 10 (in-place):\", t_shared2)  # reflects +10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLtBQl_b6qoB",
        "outputId": "b6697c6a-2f3a-4008-853c-29ea1eb97409"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor after np_array = np_array + 1 (out-of-place): tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
            "Tensor after np_array2 += 10 (in-place): tensor([11., 12., 13., 14., 15., 16., 17.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(7)        # CPU float32 by default\n",
        "np_view = t.numpy()      # shares memory with t (CPU only)\n",
        "\n",
        "print(\"Tensor:\", t)\n",
        "print(\"NumPy view:\", np_view, np_view.dtype)  # float32\n",
        "\n",
        "# In-place operation on tensor reflects in NumPy view\n",
        "t.add_(1)   # in-place\n",
        "print(\"After t.add_(1):\", t, np_view)\n",
        "\n",
        "# Out-of-place reassign breaks the link\n",
        "t = t + 1\n",
        "print(\"After t = t + 1:\", t)      # 3s\n",
        "print(\"NumPy view still:\", np_view)  # still 2s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9KiMSWo7Tj6",
        "outputId": "06eb357f-a022-4f62-8530-44a0e8578f0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([1., 1., 1., 1., 1., 1., 1.])\n",
            "NumPy view: [1. 1. 1. 1. 1. 1. 1.] float32\n",
            "After t.add_(1): tensor([2., 2., 2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2. 2. 2.]\n",
            "After t = t + 1: tensor([3., 3., 3., 3., 3., 3., 3.])\n",
            "NumPy view still: [2. 2. 2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose t_gpu lives on CUDA:\n",
        "t_gpu = torch.ones(7, device=\"cuda\")\n",
        "# Move to CPU and detach before NumPy:\n",
        "np_from_cuda = t_gpu.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "9pHMX5b47946"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed: int = 42, deterministic: bool = False, cudnn_benchmark: bool = False):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = cudnn_benchmark\n",
        "    torch.backends.cudnn.deterministic = deterministic\n",
        "\n",
        "    if deterministic:\n",
        "        try:\n",
        "            torch.use_deterministic_algorithms(True)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not enforce strict deterministic mode: {e}\")\n",
        "\n",
        "    print(f\"[Seed Set] seed={seed}, deterministic={deterministic}, cudnn.benchmark={cudnn_benchmark}\")\n",
        "\n",
        "# Example usage\n",
        "set_seed(42, deterministic=True, cudnn_benchmark=False)\n",
        "\n",
        "# Show that seeding repeats values\n",
        "torch.manual_seed(42)\n",
        "A = torch.rand(3, 4)\n",
        "torch.manual_seed(42)\n",
        "B = torch.rand(3, 4)\n",
        "print(\"A equals B everywhere?\", torch.equal(A, B))\n",
        "print(A)\n",
        "print(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqaCk0dZN14a",
        "outputId": "7506fe1b-d41f-4855-e72e-4a91e973998d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed Set] seed=42, deterministic=True, cudnn.benchmark=False\n",
            "A equals B everywhere? True\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, torch, random\n",
        "\n",
        "# reproducibility\n",
        "def seed_everything(seed=123):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    try: torch.use_deterministic_algorithms(True)\n",
        "    except: pass\n",
        "\n",
        "seed_everything(123)\n",
        "\n",
        "# numpy -> torch\n",
        "np_a = np.arange(1.0, 6.0)                 # float64\n",
        "t_view = torch.from_numpy(np_a)            # shares memory\n",
        "t_copy_f32 = t_view.float()                # breaks sharing, float32\n",
        "\n",
        "# sharing check\n",
        "np_a += 100                                # in-place -> updates t_view\n",
        "print(\"Shared tensor after np in-place:\", t_view)\n",
        "\n",
        "# torch -> numpy\n",
        "t = torch.ones(5)                           # CPU float32\n",
        "np_view = t.numpy()                         # shares memory\n",
        "t.add_(5)\n",
        "print(\"Tensor & NumPy after t.add_(5):\", t, np_view)\n",
        "\n",
        "# equality w/ seeding\n",
        "torch.manual_seed(123); X = torch.rand(2,3)\n",
        "torch.manual_seed(123); Y = torch.rand(2,3)\n",
        "print(\"X == Y everywhere?\", torch.equal(X, Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wk1NuMMPAcp",
        "outputId": "927c140d-59d8-4b33-c153-d31985291abb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shared tensor after np in-place: tensor([101., 102., 103., 104., 105.], dtype=torch.float64)\n",
            "Tensor & NumPy after t.add_(5): tensor([6., 6., 6., 6., 6.]) [6. 6. 6. 6. 6.]\n",
            "X == Y everywhere? True\n"
          ]
        }
      ]
    }
  ]
}