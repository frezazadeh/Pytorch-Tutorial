{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rUacJUBZJeH",
        "outputId": "5ddd4fa7-7a6b-4122-d04a-b104ec8518e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(42) 0 42\n",
            "tensor([2, 3]) 1 torch.Size([2])\n",
            "tensor([[ 1,  4,  9],\n",
            "        [16, 25, 36],\n",
            "        [49, 64, 81]]) 2 torch.Size([3, 3])\n",
            "tensor([[[10, 20],\n",
            "         [30, 40]]]) 3 torch.Size([1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def demo_tensors():\n",
        "    \"\"\"\n",
        "    Demo of creating tensors in PyTorch with updated numbers:\n",
        "    - scalar (0-D)\n",
        "    - vector (1-D)\n",
        "    - matrix (2-D)\n",
        "    - 3D tensor\n",
        "    Returns all four tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Scalar ---\n",
        "    scalar = torch.tensor(42)\n",
        "    # Expected console output:\n",
        "    # tensor: tensor(42)\n",
        "    # ndim:   0\n",
        "    # .item(): 42\n",
        "\n",
        "    # --- Vector ---\n",
        "    vector = torch.tensor([2, 3])\n",
        "    # Expected console output:\n",
        "    # tensor: tensor([2, 3])\n",
        "    # ndim:   1\n",
        "    # shape:  torch.Size([2])\n",
        "\n",
        "    # --- Matrix ---\n",
        "    matrix = torch.tensor([\n",
        "        [1,   4,  9],\n",
        "        [16, 25, 36],\n",
        "        [49, 64, 81]\n",
        "    ])\n",
        "    # Expected console output:\n",
        "    # tensor:\n",
        "    # tensor([[ 1,  4,  9],\n",
        "    #         [16, 25, 36],\n",
        "    #         [49, 64, 81]])\n",
        "    # ndim:   2\n",
        "    # shape:  torch.Size([3, 3])\n",
        "\n",
        "    # --- 3D Tensor ---\n",
        "    tensor3d = torch.tensor([[\n",
        "        [10, 20],\n",
        "        [30, 40]\n",
        "    ]])\n",
        "    # Expected console output:\n",
        "    # tensor shape: torch.Size([1, 2, 2])\n",
        "    # ndim:        3\n",
        "    # tensor:\n",
        "    # tensor([[[10, 20],\n",
        "    #          [30, 40]]])\n",
        "\n",
        "    return scalar, vector, matrix, tensor3d\n",
        "\n",
        "\n",
        "\n",
        "s, v, m, t = demo_tensors()\n",
        "# Uncomment to print during a live run:\n",
        "print(s, s.ndim, s.item())\n",
        "print(v, v.ndim, v.shape)\n",
        "print(m, m.ndim, m.shape)\n",
        "print(t, t.ndim, t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def tensor_playground():\n",
        "    \"\"\"\n",
        "    ğŸ² A playful tour of common PyTorch tensor creators:\n",
        "    - Random tensors (uniform 0â€“1)\n",
        "    - All zeros and all ones\n",
        "    - Sequences via arange\n",
        "    - Like-it templates with zeros_like\n",
        "    \"\"\"\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # ğŸ° 1) Random Tensor: â€œLottery Matrixâ€\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    torch.manual_seed(42)  # for reproducible â€œrandomnessâ€\n",
        "    lottery_matrix = torch.rand(size=(2, 5))\n",
        "    # Expected console output (approx.):\n",
        "    # tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
        "    #         [0.6009, 0.2566, 0.7936, 0.9408, 0.9690]])\n",
        "    # shape: torch.Size([2, 5]), dtype: torch.float32\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # ğŸ–¼ï¸ 2) Random â€œImageâ€: â€œTiny Color Patchâ€\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    torch.manual_seed(7)\n",
        "    tiny_color_patch = torch.rand(size=(4, 4, 3))\n",
        "    # Expected console output (approx.):\n",
        "    # tensor([[[0.0871, 0.1071, 0.5080],\n",
        "    #          [0.6324, 0.4901, 0.8964],\n",
        "    #          [0.7622, 0.6154, 0.4448],\n",
        "    #          [0.5196, 0.5969, 0.9684]],\n",
        "    #         â€¦ 3 more rows â€¦ ])\n",
        "    # shape: torch.Size([4, 4, 3]), ndim: 3\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # ğŸ•³ï¸ 3) All Zeros: â€œGhost Gridâ€\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    ghost_grid = torch.zeros(size=(3, 2))\n",
        "    # Expected console output:\n",
        "    # tensor([[0., 0.],\n",
        "    #         [0., 0.],\n",
        "    #         [0., 0.]])\n",
        "    # dtype: torch.float32\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # â˜ï¸ 4) All Ones: â€œCloud Arrayâ€\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    cloud_array = torch.ones(size=(2, 4))\n",
        "    # Expected console output:\n",
        "    # tensor([[1., 1., 1., 1.],\n",
        "    #         [1., 1., 1., 1.]])\n",
        "    # dtype: torch.float32\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # ğŸ”¢ 5) Sequence via arange: â€œStep Ladderâ€\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    step_ladder = torch.arange(start=5, end=15, step=3)\n",
        "    # Expected console output:\n",
        "    # tensor([ 5,  8, 11, 14])\n",
        "    # dtype: torch.int64\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # ğŸª„ 6) Texture from Template: zeros_like\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    ladder_zeros = torch.zeros_like(input=step_ladder)\n",
        "    # Expected console output:\n",
        "    # tensor([0, 0, 0, 0])\n",
        "    # dtype: torch.int64  # matches step_ladderâ€™s dtype and shape\n",
        "\n",
        "    return {\n",
        "        \"lottery_matrix\": lottery_matrix,\n",
        "        \"tiny_color_patch\": tiny_color_patch,\n",
        "        \"ghost_grid\": ghost_grid,\n",
        "        \"cloud_array\": cloud_array,\n",
        "        \"step_ladder\": step_ladder,\n",
        "        \"ladder_zeros\": ladder_zeros\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tensors = tensor_playground()\n",
        "    # To see live output, you could:\n",
        "    for name, t in tensors.items():\n",
        "      print(f\"{name} ->\", t, \"| shape:\", t.shape, \"| dtype:\", t.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04vExSTjZKR7",
        "outputId": "a892f3c0-9a50-41ff-e6cd-42f62ca50359"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lottery_matrix -> tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
            "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332]]) | shape: torch.Size([2, 5]) | dtype: torch.float32\n",
            "tiny_color_patch -> tensor([[[0.5349, 0.1988, 0.6592],\n",
            "         [0.6569, 0.2328, 0.4251],\n",
            "         [0.2071, 0.6297, 0.3653],\n",
            "         [0.8513, 0.8549, 0.5509]],\n",
            "\n",
            "        [[0.2868, 0.2063, 0.4451],\n",
            "         [0.3593, 0.7204, 0.0731],\n",
            "         [0.9699, 0.1078, 0.8829],\n",
            "         [0.4132, 0.7572, 0.6948]],\n",
            "\n",
            "        [[0.5209, 0.5932, 0.8797],\n",
            "         [0.6286, 0.7653, 0.1132],\n",
            "         [0.8559, 0.6721, 0.6267],\n",
            "         [0.5691, 0.7437, 0.9592]],\n",
            "\n",
            "        [[0.3887, 0.2214, 0.3742],\n",
            "         [0.1953, 0.7405, 0.2529],\n",
            "         [0.2332, 0.9314, 0.9575],\n",
            "         [0.5575, 0.4134, 0.4355]]]) | shape: torch.Size([4, 4, 3]) | dtype: torch.float32\n",
            "ghost_grid -> tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]]) | shape: torch.Size([3, 2]) | dtype: torch.float32\n",
            "cloud_array -> tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) | shape: torch.Size([2, 4]) | dtype: torch.float32\n",
            "step_ladder -> tensor([ 5,  8, 11, 14]) | shape: torch.Size([4]) | dtype: torch.int64\n",
            "ladder_zeros -> tensor([0, 0, 0, 0]) | shape: torch.Size([4]) | dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def dtype_showcase():\n",
        "    \"\"\"\n",
        "    A quick tour of PyTorch dtypes.\n",
        "    \"\"\"\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 1) 32-bit floating point\n",
        "    fp32 = torch.tensor([3.14, -1.23], dtype=torch.float32)\n",
        "    # Expected:\n",
        "    # tensor([ 3.1400, -1.2300], dtype=torch.float32)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 2) 64-bit floating point\n",
        "    fp64 = torch.tensor([3.14, -1.23], dtype=torch.float64)\n",
        "    # Expected:\n",
        "    # tensor([ 3.1400, -1.2300], dtype=torch.float64)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 3) 16-bit floating point (â€œhalfâ€)\n",
        "    fp16 = torch.tensor([3.14, -1.23], dtype=torch.float16)\n",
        "    # Expected:\n",
        "    # tensor([ 3.1406, -1.2295], dtype=torch.float16)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 4) 16-bit brain floating point\n",
        "    bf16 = torch.tensor([3.14, -1.23], dtype=torch.bfloat16)\n",
        "    # Expected:\n",
        "    # tensor([ 3.1406, -1.2300], dtype=torch.bfloat16)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 5) 32-bit complex\n",
        "    c32 = torch.tensor([1+2j, 3+4j], dtype=torch.complex32)\n",
        "    # Expected:\n",
        "    # tensor([1.+2.j, 3.+4.j], dtype=torch.complex32)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 6) 64-bit complex\n",
        "    c64 = torch.tensor([1+2j, 3+4j], dtype=torch.complex64)\n",
        "    # Expected:\n",
        "    # tensor([1.+2.j, 3.+4.j], dtype=torch.complex64)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 7) 128-bit complex\n",
        "    c128 = torch.tensor([1+2j, 3+4j], dtype=torch.complex128)\n",
        "    # Expected:\n",
        "    # tensor([1.+2.j, 3.+4.j], dtype=torch.complex128)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 8) 8-bit unsigned integer\n",
        "    u8 = torch.tensor([0, 255], dtype=torch.uint8)\n",
        "    # Expected:\n",
        "    # tensor([  0, 255], dtype=torch.uint8)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 9) 16-bit unsigned integer (limited support)\n",
        "    u16 = torch.tensor([0, 65535], dtype=torch.uint16)\n",
        "    # Expected:\n",
        "    # tensor([    0, 65535], dtype=torch.uint16)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 10) 32-bit unsigned integer (limited support)\n",
        "    u32 = torch.tensor([0, 2**32-1], dtype=torch.uint32)\n",
        "    # Expected:\n",
        "    # tensor([        0, 4294967295], dtype=torch.uint32)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 11) 64-bit unsigned integer (limited support)\n",
        "    u64 = torch.tensor([0, 2**64-1], dtype=torch.uint64)\n",
        "    # Expected:\n",
        "    # tensor([                  0, 18446744073709551615], dtype=torch.uint64)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 12) 8-bit signed integer\n",
        "    i8 = torch.tensor([-128, 127], dtype=torch.int8)\n",
        "    # Expected:\n",
        "    # tensor([-128,  127], dtype=torch.int8)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 13) 16-bit signed integer\n",
        "    i16 = torch.tensor([-32768, 32767], dtype=torch.int16)\n",
        "    # Expected:\n",
        "    # tensor([-32768,  32767], dtype=torch.int16)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 14) 32-bit signed integer\n",
        "    i32 = torch.tensor([-2**31, 2**31-1], dtype=torch.int32)\n",
        "    # Expected:\n",
        "    # tensor([-2147483648,  2147483647], dtype=torch.int32)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 15) 64-bit signed integer\n",
        "    i64 = torch.tensor([-2**63, 2**63-1], dtype=torch.int64)\n",
        "    # Expected:\n",
        "    # tensor([-9223372036854775808,  9223372036854775807], dtype=torch.int64)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 16) Boolean\n",
        "    b = torch.tensor([True, False, True], dtype=torch.bool)\n",
        "    # Expected:\n",
        "    # tensor([ True, False,  True])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 17) Quantized 8-bit unsigned (requires quantize_per_tensor)\n",
        "    q_u8 = torch.quantize_per_tensor(torch.tensor([0.0, 1.0]), scale=0.1, zero_point=10, dtype=torch.quint8)\n",
        "    # Expected:\n",
        "    # tensor([10, 20], size=(2,), dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 18) Quantized 8-bit signed\n",
        "    q_i8 = torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0]), scale=0.5, zero_point=0, dtype=torch.qint8)\n",
        "    # Expected:\n",
        "    # tensor([ -2,   0,   2], size=(3,), dtype=torch.qint8, quantization_scheme=torch.per_tensor_affine, scale=0.5, zero_point=0)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 19) Quantized 32-bit signed\n",
        "    q_i32 = torch.quantize_per_tensor(torch.tensor([100.0, 200.0]), scale=1.0, zero_point=0, dtype=torch.qint32)\n",
        "    # Expected:\n",
        "    # tensor([100, 200], size=(2,), dtype=torch.qint32, quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 20) Quantized 4-bit unsigned (limited support)\n",
        "    # torch.quint4x2 packs two 4-bit values per byte; usage is similar:\n",
        "    # Example placeholder (actual creation API may vary with PyTorch version):\n",
        "    # q_u4 = torch._empty_affine_quantized((2,), dtype=torch.quint4x2, scale=1.0, zero_point=0)\n",
        "    # Expected: size=(2,), dtype=torch.quint4x2 ...\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 21) 8-bit floating e4m3\n",
        "    f8_e4m3 = torch.tensor([1.0, -2.0], dtype=torch.float8_e4m3fn)\n",
        "    # Expected:\n",
        "    # tensor([ 1.0000, -2.0000], dtype=torch.float8_e4m3fn)\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 22) 8-bit floating e5m2\n",
        "    f8_e5m2 = torch.tensor([1.0, -2.0], dtype=torch.float8_e5m2)\n",
        "    # Expected:\n",
        "    # tensor([ 1.0000, -2.0000], dtype=torch.float8_e5m2)\n",
        "\n",
        "    return {\n",
        "        \"fp32\": fp32, \"fp64\": fp64, \"fp16\": fp16, \"bf16\": bf16,\n",
        "        \"c32\": c32, \"c64\": c64, \"c128\": c128,\n",
        "        \"u8\": u8, \"u16\": u16, \"u32\": u32, \"u64\": u64,\n",
        "        \"i8\": i8, \"i16\": i16, \"i32\": i32, \"i64\": i64,\n",
        "        \"bool\": b, \"q_u8\": q_u8, \"q_i8\": q_i8, \"q_i32\": q_i32,\n",
        "        # \"q_u4\": q_u4,  # uncomment if supported\n",
        "        \"f8_e4m3\": f8_e4m3, \"f8_e5m2\": f8_e5m2\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    examples = dtype_showcase()\n",
        "    # Uncomment to print:\n",
        "    for name, t in examples.items():\n",
        "      print(f\"{name}: {t} | dtype={t.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUUZeF3TlyaF",
        "outputId": "ad38236f-c155-49d4-9405-ce4ad5bcf824"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fp32: tensor([ 3.1400, -1.2300]) | dtype=torch.float32\n",
            "fp64: tensor([ 3.1400, -1.2300], dtype=torch.float64) | dtype=torch.float64\n",
            "fp16: tensor([ 3.1406, -1.2305], dtype=torch.float16) | dtype=torch.float16\n",
            "bf16: tensor([ 3.1406, -1.2266], dtype=torch.bfloat16) | dtype=torch.bfloat16\n",
            "c32: tensor([1.+2.j, 3.+4.j], dtype=torch.complex32) | dtype=torch.complex32\n",
            "c64: tensor([1.+2.j, 3.+4.j]) | dtype=torch.complex64\n",
            "c128: tensor([1.+2.j, 3.+4.j], dtype=torch.complex128) | dtype=torch.complex128\n",
            "u8: tensor([  0, 255], dtype=torch.uint8) | dtype=torch.uint8\n",
            "u16: tensor([    0, 65535], dtype=torch.uint16) | dtype=torch.uint16\n",
            "u32: tensor([         0, 4294967295], dtype=torch.uint32) | dtype=torch.uint32\n",
            "u64: tensor([                   0, 18446744073709551615], dtype=torch.uint64) | dtype=torch.uint64\n",
            "i8: tensor([-128,  127], dtype=torch.int8) | dtype=torch.int8\n",
            "i16: tensor([-32768,  32767], dtype=torch.int16) | dtype=torch.int16\n",
            "i32: tensor([-2147483648,  2147483647], dtype=torch.int32) | dtype=torch.int32\n",
            "i64: tensor([-9223372036854775808,  9223372036854775807]) | dtype=torch.int64\n",
            "bool: tensor([ True, False,  True]) | dtype=torch.bool\n",
            "q_u8: tensor([0., 1.], size=(2,), dtype=torch.quint8,\n",
            "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10) | dtype=torch.quint8\n",
            "q_i8: tensor([-1.,  0.,  1.], size=(3,), dtype=torch.qint8,\n",
            "       quantization_scheme=torch.per_tensor_affine, scale=0.5, zero_point=0) | dtype=torch.qint8\n",
            "q_i32: tensor([100., 200.], size=(2,), dtype=torch.qint32,\n",
            "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0) | dtype=torch.qint32\n",
            "f8_e4m3: tensor([ 1., -2.], dtype=torch.float8_e4m3fn) | dtype=torch.float8_e4m3fn\n",
            "f8_e5m2: tensor([ 1., -2.], dtype=torch.float8_e5m2) | dtype=torch.float8_e5m2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-524841642.py:34: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at /pytorch/aten/src/ATen/EmptyTensor.cpp:50.)\n",
            "  c32 = torch.tensor([1+2j, 3+4j], dtype=torch.complex32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Determine the device: GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example: creating a tensor of measurements with specific dtype, device, and gradient tracking\n",
        "measurement_readings = torch.tensor(\n",
        "    [1.5, 2.5, 3.5],\n",
        "    dtype=torch.bfloat16,    # 16-bit brain floating point\n",
        "    device=device,           # place tensor on the chosen device\n",
        "    requires_grad=True       # enable autograd"
      ],
      "metadata": {
        "id": "NIYvqevtop2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def tensor_comedy_club():\n",
        "    \"\"\"\n",
        "    A one-stop, funny showcase of tensor ops in PyTorch:\n",
        "    - Addition\n",
        "    - Multiplication\n",
        "    - Subtraction (with reassignment)\n",
        "    - Using torch.* funcs\n",
        "    - Element-wise ops\n",
        "    \"\"\"\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 1) Start with some â€œgalaxy scoresâ€\n",
        "    galaxy_scores = torch.tensor([4, 8, 15, 16, 23, 42])\n",
        "    # galaxy_scores: tensor([ 4,  8, 15, 16, 23, 42])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 2) Add a cosmic constant (+5)\n",
        "    uplifted = galaxy_scores + 5\n",
        "    # uplifted:      tensor([ 9, 13, 20, 21, 28, 47])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 3) Multiply by warp factor (Ã—3)\n",
        "    warp_multiplied = galaxy_scores * 3\n",
        "    # warp_multiplied: tensor([ 12,  24,  45,  48,  69, 126])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 4) Originals stay the same until reassigned!\n",
        "    # galaxy_scores still: tensor([ 4,  8, 15, 16, 23, 42])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 5) Subtract alien tax (â€“2) and reassign\n",
        "    galaxy_scores = galaxy_scores - 2\n",
        "    # galaxy_scores now: tensor([ 2,  6, 13, 14, 21, 40])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 6) Add star bonus (+10) and reassign\n",
        "    galaxy_scores = galaxy_scores + 10\n",
        "    # galaxy_scores now: tensor([12, 16, 23, 24, 31, 50])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 7) Use torch.multiply() to triple them\n",
        "    triple_torch = torch.multiply(galaxy_scores, 3)\n",
        "    # triple_torch: tensor([ 36,  48,  69,  72,  93, 150])\n",
        "\n",
        "    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "    # 8) Element-wise square (score Ã— itself)\n",
        "    galaxy_squared = galaxy_scores * galaxy_scores\n",
        "    # galaxy_squared: tensor([ 144,  256,  529,  576,  961, 2500])\n",
        "\n",
        "    return {\n",
        "        \"uplifted\": uplifted,\n",
        "        \"warp_multiplied\": warp_multiplied,\n",
        "        \"final_scores\": galaxy_scores,\n",
        "        \"triple_torch\": triple_torch,\n",
        "        \"galaxy_squared\": galaxy_squared\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = tensor_comedy_club()\n",
        "    # Uncomment to print live:\n",
        "    for name, t in results.items():\n",
        "      print(f\"{name}: {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FObJe-6K83hR",
        "outputId": "cfa39716-85af-4761-8732-21c323f150d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uplifted: tensor([ 9, 13, 20, 21, 28, 47])\n",
            "warp_multiplied: tensor([ 12,  24,  45,  48,  69, 126])\n",
            "final_scores: tensor([12, 16, 23, 24, 31, 50])\n",
            "triple_torch: tensor([ 36,  48,  69,  72,  93, 150])\n",
            "galaxy_squared: tensor([ 144,  256,  529,  576,  961, 2500])\n"
          ]
        }
      ]
    }
  ]
}